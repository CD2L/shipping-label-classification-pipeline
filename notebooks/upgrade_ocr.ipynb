{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upgrade OCR\n",
    "## Introduction\n",
    "The goal of this file is to find preprocessing ways in order to upgrade OCR's efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from models_pipeline import easyOCR\n",
    "from utils_.functions import plot_confusion_matrix, rotate_image\n",
    "from cv2 import dnn_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image as im\n",
    "from scipy.ndimage import interpolation as inter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = './utils_/data-examples/ocr/'\n",
    "OUTPUT_PATH = './outputs/'\n",
    "JSON_TEST_PATH = './utils_/data-examples/ocr/references.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(im_before, im_after):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, dpi=600)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    axes[0].imshow(im_before, cmap=\"gray\")\n",
    "    axes[0].set_title(\"Before\")\n",
    "    axes[0].axis(\"off\")\n",
    "    \n",
    "    axes[1].imshow(im_after, cmap=\"gray\")\n",
    "    axes[1].set_title(\"After\")\n",
    "    axes[1].axis(\"off\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images_couples(images_be, images_af):\n",
    "    if len(images_be) != len(images_af):\n",
    "        raise Exception('Not the same length between images_be and images_af')\n",
    "    fig, axes = plt.subplots(nrows=len(images_be), ncols=2, dpi=600)\n",
    "    fig.tight_layout\n",
    "    \n",
    "    axes[0][0].set_title('Before')\n",
    "    axes[0][1].set_title('After')\n",
    "    \n",
    "    for row,ax in enumerate(axes):\n",
    "        ax[0].imshow(images_be[row], cmap=\"gray\")\n",
    "        ax[0].axis(\"off\")\n",
    "        \n",
    "        ax[1].imshow(images_af[row], cmap=\"gray\")\n",
    "        ax[1].axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlib.Path(OUTPUT_PATH).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = os.listdir(IMAGES_PATH)\n",
    "images = []\n",
    "for file in folder:\n",
    "    if file.endswith(\".jpg\"):\n",
    "        images.append(file)\n",
    "        \n",
    "print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr = easyOCR()\n",
    "config = {\n",
    "    \"low_text\":0.5,\n",
    "    \"threshold\":0.5,\n",
    "    \"min_size\":5,\n",
    "    \"mag_ratio\":3,\n",
    "    \"paragraph\":True,\n",
    "    \"detail\":1,\n",
    "    \"bbox_min_size\":1,\n",
    "    \"contrast_ths\":0.3,\n",
    "    \"adjust_contrast\":0.5,\n",
    "    \"rotation_info\":[180]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu, process_time, n_sentences = ocr.test(JSON_TEST_PATH, IMAGES_PATH, True, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(os.path.join(IMAGES_PATH+images[0]), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "txt_fo = ocr.predict(image=image, **config)\n",
    "print(txt_fo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/pre-processing-in-ocr-fc231c6035a7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Adaptative Binarization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgf = cv2.adaptiveThreshold(image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2) #imgf contains Binary image\n",
    "\n",
    "plot_images(image, imgf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Rotation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join(IMAGES_PATH, '3.png'), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "def find_score(arr, angle):\n",
    "    data = inter.rotate(arr, angle, reshape=False, order=0)\n",
    "    hist = np.sum(data, axis=1)\n",
    "    score = np.sum((hist[1:] - hist[:-1]) ** 2)\n",
    "    return hist, score\n",
    "delta = 7\n",
    "limit = 100\n",
    "angles = np.arange(-limit, limit+delta, delta)\n",
    "scores = []\n",
    "\n",
    "for angle in angles:\n",
    "    hist, score = find_score(img, angle)\n",
    "    scores.append(score)\n",
    "    \n",
    "best_score = max(scores)\n",
    "best_angle = angles[scores.index(best_score)]\n",
    "print('Best angle: {}'.format(best_angle))# correct skew\n",
    "data = inter.rotate(img, best_angle, reshape=True, order=0)\n",
    "\n",
    "plot_images(img, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Denoizer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading image from folder where it is stored \n",
    "img = cv2.imread(os.path.join(IMAGES_PATH+images[0]), cv2.IMREAD_COLOR)\n",
    "# denoising of image saving it into dst image \n",
    "dst = cv2.fastNlMeansDenoisingColored(img, None, 5, 10, 4, 15) \n",
    "# Plotting of source and destination image \n",
    "\n",
    "plot_images(img,dst)\n",
    "print(txt_fo)\n",
    "print(ocr.predict(image=dst, **config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Denoizer + Adaptative Threshold*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)\n",
    "imgf = cv2.adaptiveThreshold(dst,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,7,2) #imgf contains Binary image\n",
    "\n",
    "plot_images(img, imgf)\n",
    "print(txt_fo)\n",
    "print(ocr.predict(image=imgf, **config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Erosion*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((2,2),np.uint8)\n",
    "gray_negative = abs(255-imgf)\n",
    "erosion = cv2.erode(gray_negative,kernel,iterations = 1)\n",
    "\n",
    "plot_images(img, abs(255-erosion))\n",
    "print(ocr.predict(image=abs(255-erosion), **config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OCR Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bboxes(bboxes, img: np.ndarray):\n",
    "    img_returned = img.copy()\n",
    "    for bbox in bboxes:\n",
    "        a,b,c,d = bbox\n",
    "        cv2.rectangle(img_returned, (a, d), (b, c), (0, 255, 0))\n",
    "    return img_returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bboxes(bboxes, img: np.ndarray, m=0):\n",
    "    img_returned = []\n",
    "    for bbox in bboxes:\n",
    "        a,b,c,d = bbox\n",
    "        print(bbox)\n",
    "        img_returned.append(img[c-m:d+m,a-m:b+m])\n",
    "    return img_returned\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr = easyOCR()\n",
    "\n",
    "res = ocr.model.detect(\n",
    "    img=img,\n",
    "    min_size=7,\n",
    "    low_text=0.5\n",
    "    )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_lst = []\n",
    "new_img_lst = []\n",
    "for image_fn in images:\n",
    "    im = cv2.imread(os.path.join(IMAGES_PATH, image_fn), cv2.IMREAD_GRAYSCALE)\n",
    "    img_lst.append(im)\n",
    "    \n",
    "    res = ocr.model.detect(\n",
    "        img=im,\n",
    "        min_size=7,\n",
    "        low_text=0.5\n",
    "    )   \n",
    "    new_img_lst.append(draw_bboxes(res[0][0], im))\n",
    "\n",
    "plot_images_couples(img_lst, new_img_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread(os.path.join(IMAGES_PATH, images[-1]), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "res = ocr.model.detect(\n",
    "    img=im,\n",
    "    min_size=7,\n",
    "    low_text=0.5\n",
    ")\n",
    "delivery_address_boxes = res[0][0][:2]\n",
    "img_bboxes = extract_bboxes(delivery_address_boxes, im)\n",
    "plot_images(im,img_bboxes[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgf = cv2.adaptiveThreshold(img_bboxes[1],255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,7, 2) #imgf contains Binary image\n",
    "\n",
    "plot_images(img_bboxes[1], imgf)\n",
    "print(ocr.predict(image=imgf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((1,2),np.uint8)\n",
    "gray_negative = abs(255-imgf)\n",
    "erosion = cv2.erode(gray_negative,kernel,iterations = 1)\n",
    "\n",
    "plot_images(img, abs(255-erosion))\n",
    "print(ocr.predict(image=abs(255-erosion)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ocr.predict(image=img_bboxes[1]))\n",
    "print(ocr.predict(image=im, **config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((2,2),np.uint8)\n",
    "gray_negative = abs(255-img_bboxes[1])\n",
    "erosion = cv2.erode(gray_negative,kernel,iterations = 1)\n",
    "\n",
    "plot_images(img_bboxes[1], abs(255-erosion))\n",
    "print(ocr.predict(image=abs(255-erosion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Downsizing interpolation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized = cv2.resize(img, (int(img.shape[1]/2),int(img.shape[0]/2)), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "plot_images(img, resized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_enhance\n",
    "\n",
    "# increase resolution by factor of 2 (e.g. 128x128 -> 256x256)\n",
    "model = torch_enhance.models.SRResNet(scale_factor=2, channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_lr = img_bboxes[1].copy()\n",
    "im_lr = im_lr.reshape(1, *im_lr.shape, 1)\n",
    "\n",
    "lr = torch.tensor(im_lr, dtype=torch.float32)\n",
    "lr = lr.permute((0,3,1,2))\n",
    "\n",
    "sr = model(lr) # [1, 3, 256, 256]\n",
    "\n",
    "img_sr = sr.permute(0,2,3,1).detach().numpy()\n",
    "\n",
    "plot_images(im_lr[0], img_sr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cee7baef5c6bf14cdead4a467fedb73b7ea41ed334ecf2098e4d0acf73d8fd13"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
